{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath_1 = 'C:\\Academic\\ECE - 4370 (Machine_Learning)\\Assignments\\Assignment_4\\Celegans_ModelGen/1'\n",
    "labelled_images = []\n",
    "for image in os.listdir(basepath_1):\n",
    "    if os.path.isfile(os.path.join(basepath_1, image)):\n",
    "        img = mpimg.imread(os.path.join(basepath_1, image))\n",
    "        # remove line below to insert 101x101 images\n",
    "        arr_img = img.reshape([10201])\n",
    "        arr_img = np.hstack((arr_img, 1))\n",
    "        labelled_images.append(arr_img)\n",
    "        \n",
    "basepath_0 = 'C:\\Academic\\ECE - 4370 (Machine_Learning)\\Assignments\\Assignment_4\\Celegans_ModelGen/0'\n",
    "for image in os.listdir(basepath_0):\n",
    "    if os.path.isfile(os.path.join(basepath_0, image)):\n",
    "        img = mpimg.imread(os.path.join(basepath_0, image))\n",
    "        arr_img = img.reshape([10201])\n",
    "        arr_img = np.hstack((arr_img, 0))\n",
    "        labelled_images.append(arr_img)\n",
    "np.random.shuffle(labelled_images)\n",
    "# W is (M+1)xK -> 2x2\n",
    "W = np.random.randn(10201+1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = W.shape[0] - 1\n",
    "k = W.shape[1]\n",
    "t = np.zeros((1, k))\n",
    "for image in labelled_images:\n",
    "    target = np.zeros(k)\n",
    "    label = image[-1]\n",
    "    target[int(label)] = 1\n",
    "    t = np.vstack((t, target))\n",
    "t = np.delete(t, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for image in labelled_images:\n",
    "    image = np.delete(image, -1, axis=0)\n",
    "    x.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x).reshape(len(x), 10201)\n",
    "x = np.hstack((x, np.ones((len(x), 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 9000\n",
    "\n",
    "x_train = x[:train_size,:]\n",
    "x_test = x[train_size:,:]\n",
    "x_train.shape\n",
    "t_train = t[:train_size,:]\n",
    "t_test = t[train_size:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = 0.0001\n",
    "max_iter = 10000\n",
    "k = W.shape[1] # num classes\n",
    "for _ in range(max_iter):\n",
    "    # error = -(1 / m) * (np.dot(t.T, np.log(y)) + np.dot((1 - t).T, np.log(1 - y)))\n",
    "    a = np.dot(x_train, W)\n",
    "    y_train = softmax(a, axis=1)\n",
    "    for j in range(k):\n",
    "        sum_error_gradient = 0\n",
    "        sum_error_gradient = np.dot((y_train[:,j] - t_train[:,j]), x_train)\n",
    "        if sum_error_gradient.all() < 10e-6:\n",
    "            break\n",
    "        error = sum_error_gradient.reshape(10202,1)\n",
    "        W[:, j:j+1] = W[:, j:j+1] - (phi * error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Developer\\ML_PR\\ML\\logistic_regression\\logistic_regression.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Developer/ML_PR/ML/logistic_regression/logistic_regression.ipynb#ch0000022?line=0'>1</a>\u001b[0m y_train[:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "y_train[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.94708697,  -4.86543632],\n",
       "       [  5.19622449,  -6.87663212],\n",
       "       [  3.86302956,  -4.375083  ],\n",
       "       ...,\n",
       "       [ -3.05194943,   3.91039999],\n",
       "       [ -2.58991169,   3.84712369],\n",
       "       [ 11.24406037, -10.78290008]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df_w = pd.DataFrame(W)\n",
    "df_w.to_csv(\"weights.csv\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = softmax(np.dot(x_test, W), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([9,9])\n",
    "for preds in y_test:\n",
    "    index = np.argmax(preds)\n",
    "    arr = np.zeros(len(preds))\n",
    "    arr[index] = 1\n",
    "    y_pred = np.vstack((y_pred, arr))\n",
    "y_pred = np.delete(y_pred, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should be very close to t\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[192 794]\n",
      "  [103 911]]\n",
      "\n",
      " [[911 103]\n",
      "  [794 192]]]\n"
     ]
    }
   ],
   "source": [
    "cf_matrix = multilabel_confusion_matrix(t_test, y_pred, labels=[False, True])\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i, preds in enumerate(y_pred):\n",
    "    if np.array_equal(preds, t_test[i]):\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5515"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct / 2000\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nfor test in classes:\\n    if test:\\n        t = np.vstack((t, [1, 0]))\\n    else:\\n        t = np.vstack((t, [0, 1]))\\nt = np.delete(t, 0, axis=0) '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is Nx(M+1) -> Nx2 \n",
    "# used to test logistic regression implementation\n",
    "\"\"\" df = pd.read_csv(\"C:\\Developer\\ML_PR\\ML\\logistic_regression\\classification.csv\")\n",
    "x = df.iloc[:,:-1]\n",
    "x = np.hstack((x, np.ones((x.shape[0],1))))\n",
    "# fix t to make it one-hot encoded\n",
    "classes = df.loc[:,'success'].astype('int64') \"\"\"\n",
    "\n",
    "\"\"\" \n",
    "for test in classes:\n",
    "    if test:\n",
    "        t = np.vstack((t, [1, 0]))\n",
    "    else:\n",
    "        t = np.vstack((t, [0, 1]))\n",
    "t = np.delete(t, 0, axis=0) \"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76cfb860b8d8296744eafcb72f209637fa1d900b396ffe522c8c85dcdb3ee4ef"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml_pr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
